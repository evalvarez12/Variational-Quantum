% !TeX encoding = UTF-8
% !TeX spellcheck = en_US
% !TeX root = report1.tex


\section{Introduction}
One of the greater problems when dealing with Quantum Mechanics is the lack for a analytical solutions for wave-functions
in almost all cases, where the harmonic oscillator and Hydrogen atom are the most notable exceptions.
Thus different number of numerical methods have been established in order to solve this type
of problem. One of these is the Variational Mont\'e Carlo method, which combines Mont\'e Carlo integration and variational
quantum mechanics in order to solve problems.


\subsection{Mont\'e Carlo Integration: Random Sampling}
\label{ch:monte}
While essentially done through means of computers, there is an 18\textsuperscript{th} century precursor to
his which nicely illustrates the idea of Mont\'e Carlo simulation. In 1733, Georges-Louis Leclerc
de Buffon had a wooden floor made up parallel beams; thus creating a plane with parallel lines.
If we were to drop down needles on the floor, he wondered what the probability would be of
any needle crossing one of the parallel lines \cite{Buffon}. Since this is dependent on the
angle the needle makes with these lines, it comes to no surprise there this is a factor of pi
in the probability. While his intentions were not to find the value of pi, this experiment
was later done to indeed find the value of pi, in 1901 by Mario Lazzarini where after 3408
tosses he found the value of pi up to 7 digits \cite{Lazzarini}.


As of the 1930s the method started to gain more popularity, especially with the advent of the computer. It comes down to using a stochastic method to determine a non-stochastic value.
In the determination of integrals with no known analytical solution, the value of the function can be calculated in a set of points and multiplied with an according area. A sum over a large number of these points can be used to obtain a good approximation of the integral. In order to minimize the computational time, it is desirable, that the number of these points is as small as possible. To still obtain good results, great care must be taken in the choice of the same. We could, for example, imagine, that an equidistant mesh could provide poor results for a cosine function, if the distance between the points has a relation with the period. When dealing with any integral its impossible to always know this in advance,
and so random sample will often provide more accurate results. Purely random points will often form clusters, which will reveal little information. Thus it appears, that starting from a grid and then moving the points a little from their original position constitutes a better strategy. This process of random shifting is called \textit{stratification} of the grid. Additionally, one can divide the space into small subspaces and, after roughly estimating the absolute value of the function in that area, adapt the number of points in that region to the value of the function. Thus areas that contribute in a more significant way to the whole integral, will have a larger number of sample points \cite{MCmethods}.

In this work we explore this idea by comparing different integration methods and observing how taking a large amount of points in a regular grid is not sufficient, and how stratification and adaptiveness in sampling can be utilized to obtain more accurate results.

\subsection{Variational Quantum Mechanics: Integrating over the space}
The variational method consists at looking at the Hilbert space of a Hamiltonian which contains all the possible states
a wave function can have in accordance to that Hamiltonian. We then restrict ourselves to a subset of this space,
and try to optimize our solution; for example by finding the ground state energy. The restriction we take is that
we use so-called trial wave functions, which are wave functions of a predetermined format with some unknown parameters,
and we try to optimize the solution in this parameter space. It turns out that \textit{the} ground state wave function
will always yield the lowest ground state energy. So when comparing two trial wave functions, the one with the lowest
energy will be closer to the \textit{actual} ground state wave function. In this way we can approximate the ground state
energy \cite{AdvStatMech}.


Our goal is to find the ground state energy of a quantum system. To this end we will
use trial wave functions $\psi_T(\textbf{r},\alpha)$, which is dependent on position $\textbf{r}$ and some parameter $\alpha$.
Notice that it is not dependent on time; we are merely interested in the ground state energy and that does not evolve over time.
In order to find the expectation value of the ground state energy we use the equation:
\begin{equation}
	\label{eq_groundstate}
	E(\alpha) = \frac{\int d\textbf{r} \psi_T^*(\textbf{r},\alpha)H\psi_T(\textbf{r},\alpha)}{\int d\textbf{r}
	 \psi_T^*(\textbf{r},\alpha)\psi_T(\textbf{r},\alpha)},
\end{equation}
Here $H$ is the Hamiltonian and $E(\alpha) \geq E_0$ is the approximation of the ground state energy which is always higher
than or equal to the actual ground state energy $E_0$.  We will also define the
\textit{local energy}
\begin{align}
	\label{eq:local_energy}
	E_L = \frac{H\psi_T(\textbf{r},\alpha)}{\psi_T(\textbf{r},\alpha)} \text{~,}
\end{align}
 which is a flat function in case
the $\psi_T(\textbf{r},\alpha) = \psi_0(\textbf{r})$. By evaluating the variance of $E_L$, we can approximate how far from
the ground state energy we are. If the variance is equal to zero we have found an exact solution. Meanwhile we can make use
this local energy as well, by simplifying equation \ref{eq_groundstate} to equation \ref{eq_groundstate2}.
\begin{equation}
	\label{eq_groundstate2}
	E(\alpha) = \frac{\int d\textbf{r} \psi_T^*(\textbf{r},\alpha)\psi_T(\textbf{r},\alpha)E_L(\textbf{r},\alpha)}{\int d\textbf{r} \psi_T^*(\textbf{r},\alpha)\psi_T(\textbf{r},\alpha)}
\end{equation}
which is easier to work with due to the lack of a Hamiltonian \cite{JosBook}. These integrals are then evaluated using
the described Mont\'e Carlo method.


%In order to make the best use of finite integration steps, we will sample not \textit{entirely} at random, but rather by iteratively in such a way that we place our finite sample points there where the wave function is non-zero. This is called an adaptive method, and we will show that this yields better results quicker than using an entirely random sample, as seen in the next chapter.
In order to calculate the variance of the local energy, we take
$Var(E_L) = \sqrt{<E_L^2> - <E_L>^2} = \sqrt{ \int \textbf{r}^2 E_L(\textit{r},\alpha) d\textbf{r} -
(\int \textbf{r} E_L(\textit{r},\alpha)d\textbf{r})^2 } $, %TODO!!!
which can either be solves analytically or numerically, depending on the form of the local energy.

In order to find the minimum value of the energy with respect to $\alpha$ we use Newton's method on the derivative $\frac{dE}{d\alpha} = 2 (\left< E_L \frac{d \ln(\Psi_T)}{d \alpha} \right> - E\left<\frac{d \ln(\Psi_T)}{d \alpha}\right>)$. This method works because our the exact solution is within the family of trial functions, see \cite{JosBook}. %TODO
The new variational parameter can then be adapted as $$\alpha_{\text{new}} = \alpha_{\text{old}} - \gamma \frac{dE}{d\alpha} \text{~.} $$


%TODO: Not sure if this is appropriate in a paper
%This work is as follows, chapter 2 contains a theoretical description of the quantum problems we attempt to solve. In chapter 3 we explore through different numerical integration methods comparing each other in order to conclude which one is the best. Next in chapter 4, we describe our results and discuss them in the light of expectations. Finally, in chapter 5 we will draw conclusions and suggest options for further research.
